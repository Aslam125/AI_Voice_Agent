import os
from agentscope.agent import ReActAgent
from agentscope.model import OpenAIChatModel
from agentscope.tts import GeminiTTSModel
from agentscope.formatter import OpenAIChatFormatter
from agentscope.message import Msg
from dotenv import load_dotenv

load_dotenv()

class VoiceAgentManager:
    def __init__(self):
        # 1. Setup the Brain using GitHub Models (OpenAI Compatible)
        # Using GitHub token and its custom base URL
        self.brain = OpenAIChatModel(
            model_name="gpt-4o", 
            api_key=os.getenv("GITHUB_TOKEN"),
            client_kwargs={
                "base_url": "https://models.inference.ai.azure.com"
            }
        )
        
        # 2. Setup the Voice using Google Gemini
        # Gemini provides high-quality speech generation
        self.voice = GeminiTTSModel(
            api_key=os.getenv("GEMINI_API_KEY"),
            model_name="gemini-2.5-flash-preview-tts", # Optimized for TTS
            voice="Kore", # Professional sounding voice
            stream=False
        )
        
        # 3. Initialize the ReAct Agent
        # This agent can think, use tools, and speak.
        self.agent = ReActAgent(
            name="Friday",
            model=self.brain,
            formatter=OpenAIChatFormatter(),
            tts_model=self.voice,
            sys_prompt=(
                "You are 'Friday', a highly intelligent voice assistant. "
                "Keep your answers extremely brief, conversational, and helpful. "
                "Do not use any markdown like bold or bullet points in your speech."
            )
        )

    async def get_response(self, text: str):
        """
        Processes text through the ReAct agent and returns both text and audio.
        """
        # Wrap user input in AgentScope message format
        user_msg = Msg("User", text, role="user")
        
        # The agent performs reasoning (and tool use if tools are added)
        # It also automatically triggers the TTS model because we provided it in __init__
        reply_msg = await self.agent(user_msg)
        
        # Extract the spoken text
        text_reply = reply_msg.get_text_content()
        
        # Extract audio generated by Gemini TTS
        audio_blocks = reply_msg.get_content_blocks("audio")
        audio_base64 = ""
        
        if not audio_blocks:
            # Fallback: Manually synthesize if agent didn't attach it
            tts_res = await self.voice.synthesize(reply_msg)
            if tts_res.content:
                audio_blocks = [tts_res.content]

        if audio_blocks:
            block = audio_blocks[0]
            # Handle both object and dictionary formats
            source = getattr(block, 'source', None) or (block.get('source') if isinstance(block, dict) else None)
            if source:
                audio_base64 = getattr(source, 'data', None) or (source.get('data', "") if isinstance(source, dict) else "")
            
        return {
            "text": text_reply,
            "audio": audio_base64
        }
